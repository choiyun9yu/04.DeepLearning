{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM\n",
        "\n",
        "- 워드 임베딩 : 단어의 의미를 벡터화하는 것(주로 희소표현인 원핫인코딩에서 밀집표현으로 변환하는 것을 의미)\n",
        "- 비슷한 의미 지는 것 끼리 모아서 비슷한 숫자 배정하는 것으 밀집표현 "
      ],
      "metadata": {
        "id": "dAbRo_EZliD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로드"
      ],
      "metadata": {
        "id": "Bz-rGBtLCu9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "z-ad7S8GlkEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 많이 나온 단어 상위 1000개만 출력\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = 1000, test_split = 0.2)"
      ],
      "metadata": {
        "id": "a0GeFxJilkGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWXvzGR-lkIk",
        "outputId": "3c239c80-15a6-462c-e5aa-b152664ee6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 2,\n",
              " 8,\n",
              " 43,\n",
              " 10,\n",
              " 447,\n",
              " 5,\n",
              " 25,\n",
              " 207,\n",
              " 270,\n",
              " 5,\n",
              " 2,\n",
              " 111,\n",
              " 16,\n",
              " 369,\n",
              " 186,\n",
              " 90,\n",
              " 67,\n",
              " 7,\n",
              " 89,\n",
              " 5,\n",
              " 19,\n",
              " 102,\n",
              " 6,\n",
              " 19,\n",
              " 124,\n",
              " 15,\n",
              " 90,\n",
              " 67,\n",
              " 84,\n",
              " 22,\n",
              " 482,\n",
              " 26,\n",
              " 7,\n",
              " 48,\n",
              " 4,\n",
              " 49,\n",
              " 8,\n",
              " 864,\n",
              " 39,\n",
              " 209,\n",
              " 154,\n",
              " 6,\n",
              " 151,\n",
              " 6,\n",
              " 83,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 155,\n",
              " 11,\n",
              " 15,\n",
              " 7,\n",
              " 48,\n",
              " 9,\n",
              " 2,\n",
              " 2,\n",
              " 504,\n",
              " 6,\n",
              " 258,\n",
              " 6,\n",
              " 272,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 134,\n",
              " 44,\n",
              " 11,\n",
              " 15,\n",
              " 16,\n",
              " 8,\n",
              " 197,\n",
              " 2,\n",
              " 90,\n",
              " 67,\n",
              " 52,\n",
              " 29,\n",
              " 209,\n",
              " 30,\n",
              " 32,\n",
              " 132,\n",
              " 6,\n",
              " 109,\n",
              " 15,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자와 문자를 매칭시켜주는 코드\n",
        "word_index = reuters.get_word_index()\n",
        "index_to_word={}\n",
        "for key, value in word_index.items():\n",
        "    index_to_word[value] = key"
      ],
      "metadata": {
        "id": "WTb4QVdtlkK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mxkvdwpLlkNR",
        "outputId": "a963505f-e371-44ee-de26-debae063061f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 46가지로 뉴스를 분류\n",
        "max(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYRyqGtBlkPe",
        "outputId": "d418632a-9038-4668-bf7d-0f3ce567f932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "74q7npHICzX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 뉴스마다 길이가 다름\n",
        "print(len(X_train[1]))\n",
        "print(len(X_train[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn9tKwailkR1",
        "outputId": "51d76e9e-d372-44e9-b0d4-d03391e5a7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n",
            "139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 긴 뉴스의 길이\n",
        "print(max(len(i) for i in X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRZN_dFilkT8",
        "outputId": "2125af58-55b5-4f84-af6d-0a5eecbfc767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 뉴스의 평균 길이\n",
        "print(sum(map(len, X_train))/len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFY5ERA7lkWp",
        "outputId": "3d5b2dd8-1cd8-4c43-ab73-9b26b6df6816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145.5398574927633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jqadhrADpAvd",
        "outputId": "14bb6401-eaac-421d-8d34-cbcb1904339d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 뉴스의 단어수를 145로 맞춰줌\n",
        "# 짧은 건 앞에 0으로 공백 채우기, 긴 건짜르기\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=145)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=145)"
      ],
      "metadata": {
        "id": "rjPaN_Q8pAx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT7bYbuOA8e5",
        "outputId": "0da78ef4-11c6-4a13-e591-e957792bafd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982, 145), (2246, 145))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EefX75YQA8g0",
        "outputId": "cd4c21fe-e156-4653-c2d8-d04e7ed9c944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   1,   2,   2,   8,  43,  10, 447,\n",
              "         5,  25, 207, 270,   5,   2, 111,  16, 369, 186,  90,  67,   7,\n",
              "        89,   5,  19, 102,   6,  19, 124,  15,  90,  67,  84,  22, 482,\n",
              "        26,   7,  48,   4,  49,   8, 864,  39, 209, 154,   6, 151,   6,\n",
              "        83,  11,  15,  22, 155,  11,  15,   7,  48,   9,   2,   2, 504,\n",
              "         6, 258,   6, 272,  11,  15,  22, 134,  44,  11,  15,  16,   8,\n",
              "       197,   2,  90,  67,  52,  29, 209,  30,  32, 132,   6, 109,  15,\n",
              "        17,  12], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라베데이터 원핫인코딩\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_en =  to_categorical(y_train)\n",
        "y_test_en = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "iT4socQwA8jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_en.shape, y_test_en.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAFBppiMA8lT",
        "outputId": "a6506287-483a-4c82-beda-f4fc5da2452a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982, 46), (2246, 46))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM 모델 만들기"
      ],
      "metadata": {
        "id": "OYo81IgAC16i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "\n",
        "# 임베딩 층 (단어를 희소표현에서 밀집표현으로 변경 = 워드 임베딩)\n",
        "# Embedding(사용된 단어의 개수, 기사당 단어수)\n",
        "model1.add(Embedding(1000, 145))\n",
        "\n",
        "# LSTM층\n",
        "model1.add(LSTM(100, activation='tanh'))\n",
        "\n",
        "# \n",
        "model1.add(Dense(46, activation='softmax'))"
      ],
      "metadata": {
        "id": "l1tLRC92pA0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "51R8iHCtpA2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train, y_train_en, epochs=50)"
      ],
      "metadata": {
        "id": "-zcsoDe4pA4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비교를 위해 RNN 돌려보기\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN\n",
        "model2 = Sequential()\n",
        "# 단어를 희소표현에서 밀집표현으로 변경 = 워드임베딩\n",
        "model2.add(Embedding(1000,145)) # 사용된 단어의 갯수(1000), 기사당 단어수(145)\n",
        "model2.add(SimpleRNN(100,input_shape=(1000,145), activation = 'tanh'))\n",
        "model2.add(Dense(46, activation = 'softmax'))\n",
        "model2.compile(loss = 'categorical_crossentropy',\n",
        "               optimizer = 'adam',\n",
        "               metrics = ['accuracy'])\n",
        "model2.fit(X_train,y_train, epochs = 20)"
      ],
      "metadata": {
        "id": "-VryKDuapA9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention"
      ],
      "metadata": {
        "id": "jslLvDxiRuSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM도 tanh의 한계로 뒤에 있는 말들이 더기억이 많이 됨\n",
        "# Attention : 중간중간 가중치를 계산하고 문맥에 중심단어에 높은 가중치 부여"
      ],
      "metadata": {
        "id": "PTudkwdbpA_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install attention\n",
        "from attention import Attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScTfLe2sRDW5",
        "outputId": "c466a90a-a3d9-45b6-b655-b309e1cb2dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting attention\n",
            "  Downloading attention-4.1-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from attention) (1.21.6)\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.7/dist-packages (from attention) (2.9.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.9.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.9.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.27.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.49.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.3.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1->attention) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.1->attention) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.2.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.1->attention) (3.0.9)\n",
            "Installing collected packages: attention\n",
            "Successfully installed attention-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM + Attention \n",
        "model3 = Sequential()\n",
        "\n",
        "# 단어를 희소표현에서 밀집표현으로 변경 = 워드임베딩\n",
        "model3.add(Embedding(1000,145)) # 사용된 단어의 갯수(1000), 기사당 단어수(145)\n",
        "model3.add(LSTM(100, activation = 'tanh', return_sequences = True))\n",
        "model3.add(Attention())\n",
        "model3.add(Dense(46, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "qmm0BSOsRDZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss = 'categorical_crossentropy',\n",
        "               optimizer = 'adam',\n",
        "               metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "1hclR4TnRDbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(X_train,y_train, epochs = 20)"
      ],
      "metadata": {
        "id": "xjruZqvnRDeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZSY4_iuRDgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWo-f5oyR4NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xjZpxneR4P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKwBh_1BR4SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYdPLYKkR4U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsZGcauxR4XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bpLYpY4uR4Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CphP6dpjR4eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wLNHj1IR4g-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}